---
model: 'Transformer'
dst_vocab: '/data/nfs_ssd/xuyang1/transformer-iacas/exp/librispeech/fbank_cleaned/vocab.txt'
dst_vocab_size: 30
#### hidden_units: 512
hidden_units: 1024
scale_embedding: True
tie_embedding_and_softmax: True
attention_dropout_rate: 0.0
#### residual_dropout_rate: 0.1
residual_dropout_rate: 0.3
num_blocks: 6
#### num_heads: 8
num_heads: 16
ff_activation: 'glu'
model_dir: '/data/nfs_ssd/xuyang1/transformer-iacas/exp/librispeech/fbank_cleaned/model'
bucket_min: 50
bucket_max: 10000
bucket_step: 10
is_attention_smoothing: False
train:
    num_gpus: 4
    tokens_per_batch: 10000
    src_path: '/data/nfs_ssd/xuyang1/transformer-iacas/exp/librispeech/fbank_cleaned/feats.scp'
    dst_path: '/data/nfs_ssd/xuyang1/transformer-iacas/exp/librispeech/fbank_cleaned/text_char'
    max_length: 2000
    num_epochs: 20
    num_steps: 300000
    save_freq: 200
    show_freq: 1
    summary_freq: 100
    grads_clip: 5
    optimizer: 'adam_decay'
    learning_rate: 1
    warmup_steps: 12000
    label_smoothing: 0.1
    toleration: 10
    eval_on_dev: False
#    input_dim: 129
#    input_dim: 516
    input_dim: 80
    var_filter: ''
dev:
    batch_size: 128
    src_path:
    ref_path:
    output_path:

test:
    batch_size: 100
    max_target_length: 200
    lp_alpha: 0.6
    beam_size: 13
    num_gpus: 4

    set1:
        src_path: '/data/nfs_ssd/xuyang1/transformer-iacas/exp/librispeech/fbank_cleaned/feats_dev_clean.scp'
        ref_path: '/data/nfs_ssd/xuyang1/transformer-iacas/exp/librispeech/fbank_cleaned/text_dev_clean_char'
        output_path: '/data/nfs_ssd/xuyang1/transformer-iacas/exp/librispeech/fbank_cleaned/decoder_dev_clean.txt'
        cmd:
